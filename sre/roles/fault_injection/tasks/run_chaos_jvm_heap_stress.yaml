---
- name: Document this fault injection
  set_fact:
    injection_docs: "{{ injection_docs | default([]) + [curr_docs] }}"
  vars:
    curr_docs:
      name: "Chaos JVM Heap Stress"
      author: "@divyapathak24"
      description: "Create jvmchaos to induce heap stress on adservice"
      fault_type: "ChaosMesh"
      required_fields:
        - "chaos_mesh_namespace_project_name"
        - "otel_astronomy_app_namespace_project_name"
        - "target_deployment_name"
        - "target_label_name1"
        - "target_namespace_name"
        - "deployment_info.result.spec.template.spec.containers[0].name"
        - "deployment_info.result.spec.template.spec.containers[0].image"
        - "deployment_info.result.spec.template.spec.containers[0].resources.limits.memory"
  tags:
    - injection_docs

- name: Get current deployment
  kubernetes.core.k8s:
    api_version: apps/v1
    kind: Deployment
    namespace: "{{ otel_astronomy_app_namespace_project_name }}"
    name: "{{ target_deployment_name }}"
    kubeconfig: "{{ kubeconfig }}"
  register: deployment_info
  tags: incident_35
  when: is_jvm_heap_chaos and is_fault_injection

- name: Create a new variable with the name to get the service first name
  set_fact:
    new_service_name: "{{ target_label_name1 | replace('service', '') | upper }}"
  tags: incident_35
  when: is_jvm_heap_chaos

- name: Create Job from Deployment
  kubernetes.core.k8s:
    kubeconfig: "{{ kubeconfig }}"
    state: present
    definition:
      apiVersion: batch/v1
      kind: Job
      metadata:
        name: "{{ target_deployment_name }}"
        namespace: "{{ otel_astronomy_app_namespace_project_name }}"
        labels:
          app.kubernetes.io/component: "{{ target_label_name1 }}"
          app.kubernetes.io/instance: "{{ otel_astronomy_app_namespace_project_name }}"
          app.kubernetes.io/name: "{{ target_label_name1 }}"
      spec:
        template:
          metadata:
            labels:
              app.kubernetes.io/component: "{{ target_label_name1 }}"
              app.kubernetes.io/instance: "{{ otel_astronomy_app_namespace_project_name }}"
              app.kubernetes.io/name: "{{ target_label_name1 }}"
          spec:
            containers:
              - name: "{{ deployment_info.result.spec.template.spec.containers[0].name }}"
                image: "{{ deployment_info.result.spec.template.spec.containers[0].image }}"
                imagePullPolicy: IfNotPresent
                ports:
                  - containerPort: 8080
                    name: "{{ target_label_name1 }}"
                    protocol: TCP
                env:
                  - name: OTEL_SERVICE_NAME
                    valueFrom:
                      fieldRef:
                        apiVersion: v1
                        fieldPath: "metadata.labels['app.kubernetes.io/component']"
                  - name: OTEL_COLLECTOR_NAME
                    value: "otel-collector"
                  - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
                    value: cumulative
                  - name: '{{new_service_name}}_SERVICE_PORT'
                    value: "8080"
                  - name: FLAGD_HOST
                    value: "flagd"
                  - name: FLAGD_PORT
                    value: "8013"
                  - name: OTEL_EXPORTER_OTLP_ENDPOINT
                    value: http://$(OTEL_COLLECTOR_NAME):4318
                  - name: OTEL_LOGS_EXPORTER
                    value: otlp
                  - name: OTEL_RESOURCE_ATTRIBUTES
                    value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.1
                  - name: JAVA_OPTS
                    value: "-Xmx256M -Xms256M"
                resources:
                  limits:
                    memory: "{{ deployment_info.result.spec.template.spec.containers[0].resources.limits.memory }}"
                securityContext:
                  runAsGroup: 1000
                  runAsNonRoot: true
                  runAsUser: 999
            restartPolicy: Never
        backoffLimit: 0
  tags: incident_35
  when: is_jvm_heap_chaos and is_fault_injection

- name: Get current service information
  kubernetes.core.k8s:
    kubeconfig: "{{ kubeconfig }}"
    kind: Service
    name: "{{ target_deployment_name }}"
    namespace: "{{ otel_astronomy_app_namespace_project_name }}"
  register: svc_info
  tags: incident_35
  when: is_jvm_heap_chaos and is_fault_injection

- name: Delete save the deployment spec in /tmp/jvm_heap_deployment.yaml and delete deployment and svc
  ansible.builtin.shell: |
    kubectl get deployment/'{{ target_deployment_name }}' -n  {{ otel_astronomy_app_namespace_project_name }} -o yaml > /tmp/jvm_heap_deployment.yaml
    kubectl delete deployment/'{{ target_deployment_name }}' -n {{ otel_astronomy_app_namespace_project_name }}
    kubectl delete service/'{{ target_deployment_name }}' -n {{ otel_astronomy_app_namespace_project_name }}
  tags: incident_35
  when: is_jvm_heap_chaos and is_fault_injection

- name: Create a service
  kubernetes.core.k8s:
    kubeconfig: "{{ kubeconfig }}"
    state: present
    definition:
      apiVersion: v1
      kind: Service
      metadata:
        name: "{{ target_deployment_name }}"
        namespace: "{{ otel_astronomy_app_namespace_project_name }}"
        labels:
            app.kubernetes.io/component: "{{ target_label_name1 }}"
            app.kubernetes.io/instance: "{{ otel_astronomy_app_namespace_project_name }}"
            app.kubernetes.io/name: "{{ target_label_name1 }}"
      spec:
        clusterIP: "{{ svc_info.result.spec.clusterIP }}"
        selector:
          app.kubernetes.io/name: "{{ target_deployment_name }}"
        ports:
        - port: 8080
          targetPort: 8080
  tags: incident_35
  when: is_jvm_heap_chaos and is_fault_injection

- name: Inject JVM heap stress chaos leveraging the Chaos framework
  kubernetes.core.k8s:
    state: present
    kubeconfig: "{{ kubeconfig }}"
    definition:
      apiVersion: chaos-mesh.org/v1alpha1
      kind: Schedule
      metadata:
        name: "schedule-jvmheapstress-{{ target_deployment_name }}"
        namespace: "{{ tools_helm_releases.chaos_mesh.namespace }}"
      spec:
        schedule: "* * * * *"
        historyLimit: 1
        concurrencyPolicy: "Forbid"
        type: "JVMChaos"
        jvmChaos:
          mode: all
          selector:
            namespaces:
              - "{{ target_namespace_name }}"
            labelSelectors:
              "app.kubernetes.io/component": "{{ target_label_name1 }}"
          action: stress
          memType: 'heap'
          duration: "55s"
  register: fault_injection_status
  tags: chaos-mesh
  when: is_jvm_heap_chaos and is_fault_injection

- name: Remove JVM heap stress chaos leveraging the Chaos framework
  kubernetes.core.k8s:
    state: absent
    kubeconfig: "{{ kubeconfig }}"
    definition:
      apiVersion: chaos-mesh.org/v1alpha1
      kind: Schedule
      metadata:
        name: "schedule-jvmheapstress-{{ target_deployment_name }}"
        namespace: "{{ tools_helm_releases.chaos_mesh.namespace }}"
  register: fault_removal_status
  tags: chaos-mesh
  when: is_jvm_heap_chaos and is_fault_removal

- name: Get current job
  kubernetes.core.k8s:
    api_version: batch/v1
    kind: Job
    namespace: "{{ otel_astronomy_app_namespace_project_name }}"
    name: "{{ target_deployment_name }}"
    kubeconfig: "{{ kubeconfig }}"
  register: job_info
  tags: incident_35
  when: is_jvm_heap_chaos and is_fault_removal

- name: Delete the job
  ansible.builtin.shell: |
    kubectl delete job/'{{ target_deployment_name }}' -n {{ otel_astronomy_app_namespace_project_name }}
  tags: incident_35
  when: is_jvm_heap_chaos and is_fault_removal

- name: Reapply the deployment
  ansible.builtin.shell: |
    kubectl apply -f /tmp/jvm_heap_deployment.yaml -n  {{ otel_astronomy_app_namespace_project_name }}
  tags: incident_35
  when: is_jvm_heap_chaos and is_fault_removal

- name: Remove /tmp/jvm_heap_deployment files
  ansible.builtin.shell: |
    rm -f '/tmp/jvm_heap_deployment.yaml'
  tags: incident_35
  when: is_jvm_heap_chaos and is_fault_removal
